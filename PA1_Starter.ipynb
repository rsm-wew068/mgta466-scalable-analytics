{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqK72jxWInfq"
   },
   "source": [
    "# MGTA 466: Programming Assignment 1\n",
    "\n",
    "## Setup of PySpark\n",
    "\n",
    "#### Tasks: \n",
    "\n",
    "* Verify that the installation is correct - Follow instructions in this notebook\n",
    "* Read to/from HDFS, perform spark dataframe operations, write to/from HDFS\n",
    "\n",
    "#### Submission on Gradescope:\n",
    "  * You need to submit the following files under \"PA1\"\n",
    "      * The current notebook - **PA1_Starter.ipynb**\n",
    "      * File containing first 31 lines of the result(Instructions given below) - **results_30.txt**\n",
    "      \n",
    "#### IMPORTANT submission guidelines enforced by autograder. Please read carefully:\n",
    "  * Make sure that all the cells in this notebook are executed before submission\n",
    "  * Some cells are maked **DO NOT DELETE**. These cells cannot be deleted and the output of these cells will be used for autograding\n",
    "  * You can add cells or delete(NOT recommended) other cells, but the **Expected Output** for each of the tasks MUST be the output of the cells marked as such\n",
    "  * DO NOT print anything other than the *exact* expected output. Do not include any sentences describing the output. This is strictly enforced by the autograder which checks for an *exact* match of the expected output. For example, if you are expected to print the PySpark version:\n",
    "      * '10.9.8' - <span style=\"color:#093\">CORRECT</span>\n",
    "      * 'The PySpark version is 10.9.8' - <span style=\"color:#FF0000\">INCORRECT</span>\n",
    "  * You can add cells for printing debugging information anywhere, but do not print anything else in **Expected Output** cells other than the expected output for the task\n",
    "---\n",
    "\n",
    "Remember: when in doubt, read the documentation first. It's always helpful to search for the class that you're trying to work with, e.g. pyspark.sql.DataFrame. \n",
    "\n",
    "PySpark API Documentation: https://spark.apache.org/docs/latest/api/python/index.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress native-hadoop warning\n",
    "!sed -i '$a\\# Add the line for suppressing the NativeCodeLoader warning \\nlog4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR,console' /$HADOOP_HOME/etc/hadoop/log4j.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPEAXaZBInft"
   },
   "source": [
    "### 1. Copy data file(s) to HDFS\n",
    "\n",
    "Spark can work with many data sources, including the Hadoop File System (HDFS). Here are the steps (assuming you have opened your jupyter-lab in the container) you need to copy files between the local file system and HDFS:\n",
    "\n",
    "<ol>\n",
    "    <li type =\"a\">Using the File Browser on the left, navigate to the working folder. We suggest maintaining a separate folder for each assignment.</li>\n",
    "    <li type =\"a\">Upload this notebook <code>PA1_Starter.ipynb</code> and the data file <code>BookReviews_1M.txt</code> to your working folder.</li>\n",
    "    <li type =\"a\">Open a terminal by navigating to <code>Terminal</code> &#8594; <code>New Terminal</code>. <code>cd</code> to your working folder.</li>\n",
    "    <li type =\"a\">Initialize and start up HDFS, similar to the demo from class.\n",
    "    </li>\n",
    "    <li type =\"a\"> Now copy the  <code>BookReviews_1M.txt</code> datafile from your local system to the root of the Hadoop File System, similar to the demo from class.</li>\n",
    "    <li type =\"a\"> Run <code>hdfs dfs -ls /</code> to list the files and check that the file was copied.</li>\n",
    "</ol>\n",
    "\n",
    "#### **Expected output**: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uvGPNDdInfu"
   },
   "source": [
    "### 2. Start Spark Session - 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the Spark session with a configuration for local execution, then output the pyspark version.  Remember to first import PySpark and SparkSession."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SY9e9xsHInfu"
   },
   "source": [
    "#### **Expected output** - PySpark version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "457245a7-a02e-462d-a565-7f90ba2a2c51",
    "deletable": false,
    "editable": true,
    "id": "eIfVaCCqInfv",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf().setAll([\n",
    "\t('spark.master', 'local[1]'),\n",
    "\t('spark.app.name', 'App Name')\n",
    "])\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDm0Drx1Infv"
   },
   "source": [
    "### 3. Load Data - 1 point\n",
    "\n",
    "Read data from the `BookReviews_1M.txt` file on HDFS, and print the number of rows in that dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l1qXffaInfw"
   },
   "source": [
    "#### **Expected output**: Number of rows of the dataframe i.e. number of lines in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "ed8e3458-1ee6-4823-99d2-905e980b439a",
    "deletable": false,
    "editable": true,
    "id": "NOgiNgEiInfw",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows of the dataframe i.e. number of lines in the file\n",
    "df = spark.read.text(\"hdfs:///Demo1-HDFS/BookReviews_1M.txt\").cache()\n",
    "df.head()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToaS-_52Infw"
   },
   "source": [
    "### 4. Examine the data - 2 points\n",
    "\n",
    "Examine the contents of the dataframe that you've just read from file.\n",
    "\n",
    "Expected output: \n",
    "<ol>\n",
    "    <li type = \"a\">Schema of the raw dataframe</li>\n",
    "    <li type = \"a\">First 10 rows of the dataframe</li>\n",
    "    <li type = \"a\">First 10 rows of the dataframe showing the <b>entire</b> sentence. Pass <code>truncate=False</code> as argument to <code>DataFrame.show</code> to see the entire sentence.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7Wf2IMeInfx"
   },
   "source": [
    "#### **Expected output**: Schema of the raw dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "fec5a53d-631c-40a3-ad05-2b9bd75540ab",
    "deletable": false,
    "editable": true,
    "id": "TAsapba5Infx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Expected output**: First 10 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|This was the firs...|\n",
      "|Also after going ...|\n",
      "|As with all of Ms...|\n",
      "|I've not read any...|\n",
      "|This romance nove...|\n",
      "|Carolina Garcia A...|\n",
      "|Not only can she ...|\n",
      "|Once again Garcia...|\n",
      "|The timing is jus...|\n",
      "|Engaging. Dark. R...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYzMbwToInfx"
   },
   "source": [
    "#### **Expected output**: First 10 rows of the dataframe showing the entire sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "3b8a5cbe-75e0-464b-9623-0d8d3767f310",
    "deletable": false,
    "editable": true,
    "id": "dIZYgSASInfy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|This was the first time I read Garcia-Aguilera.  I came upon the name of this book on Live with Regis and Kelly. This book was exactly what I was looking for ... it hit the spot.  I really enjoyed this book because it was well written. Once I started this book it kept me coming back for more. It had culture, family, friendship and romance. I was looking for a little more romance when I picked this book but in the end it turned out to be just right.  I love the main chartachter Margarita (aka Daisy). I've never been to Miami but the way Daisy told the story I certainly felt I'd been there.                                                                                                                                                                                                                                                                                                                            |\n",
      "|Also after going through all of Daisy's perils ... I closed the book with a feeling I had grown emotionally as well.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|As with all of Ms. Garcia-Aguilera's books, I think this is a MUST READ, impossible to put down. Successful deviation from past Lupe Solano series-captures the very essence of the excitement, local color and diverse fabric of MIAMI. Sensual and culturally enlightened!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|I've not read any of Ms Aguilera's works before, but after having just finished One Hot Summer I'm going to check out the Lupe Solano series I've heard so much about.  One Hot Summer is sooo steamy! Made me want to move to Miami!  Couldn't put the book down.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|This romance novel is right up there with the rest of her amazing mystery novels.  Being a guy, I was a little hesitant about reading a romance novel but I just had to give this book a shot because I have been such a huge fan of Garcia-Aguilera's books.  And to be honest, I absolutely loved this book.  I love the way she presents funky Miami and its crazy Cubans in not just this book but all her books.  Garcia-Aguilera did a superb job with this book, and I can't wait till her next book.  You gotta read this book!!!!                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|Carolina Garcia Aguilera has done it again.  She's written another highly enjoyable book and infused it with the right amount of Cuban-American tidbits.  My family and I cannot put her books down once we start and this one was not a let down.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|Not only can she write mysteries,but she sure can write a love story! This was \"ONE HOT SUMMER\" read that I couldn't put down !!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "|Once again Garcia-Aguilera has written a book that I just can't put down. I have read and love all her mysteries- so I picked up this romance with eager anticipation. I was not disappointed. The main character Margarita is easily likeable, which makes the trials she faces that much more intriguing. Sometimes you want to yell at the book and tell Margarita what she should (and shouldn't) do. But the author is measured in the development of the plot and keeps you turning the pages all the way to the end. Mix that in with an interesting take on Cuban exile politics and humorous insights on the world around Margarita and the picture of wild, steamy Miami is complete. Another winner from Garcia-Aguilera.                                                                                                                                                                                                           |\n",
      "|The timing is just right for a good book. Actually, it's long overdue. Therefore, I highly recommend you read this book. I promise you won't be disappointed. If this doesn't make the bestsellers list something is definitely wrong here. This well written story is so engaging, funny, almost true, etc. The character Beryl was funny and sad. Unfortunately, there are women just like her and people take advantage of them. What we won't do for love. Penn said, women can be so stupid. He told her he love her on their first night together and she belived him. That was her demise right there.                                                                                                                                                                                                                                                                                                                                  |\n",
      "|Engaging. Dark. Reading the book you could almost feel the train wreck about to happen.  The collision of characters is painful yet stimulating.  Files show the depth of her writing in this book especially by showcasing her ethnically diverse cast.  It wasn't what I was expecting, but if you can get past the initial character introductions you'll be hooked!  The sex and graphic violence can be overwhelming and hard to stomach, but it's what makes this book...the book.  If you like tidiness this isn't the book for you...it's everything, but tidy.  Personally, I was slightly disappointed in the final direction of the book, but from a literary perspective this is close to a masterpiece.  Her books just keep getting better and better.  This one really pushes the reader mentally and educationally through her use of real literary terms and vocabulary words that may require a quick tour through Webster's.|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEvxHl4sInfy"
   },
   "source": [
    "### 5. Get the first 100 characters of text in each row of the data and convert them to lowercase - 2 points\n",
    "\n",
    "<ol>\n",
    "    <li type =\"a\">Get the first 100 characters of text in each row of the dataframe and convert them to lowercase.</li>\n",
    "    <li type =\"a\">Alias/Rename the resulting column name to <code>lowerfirst100</code> in the new dataframe</li>\n",
    "    <li type =\"a\">Useful functions - <p><a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.substring.html#pyspark.sql.functions.substring\">substring</a>, <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.alias.html\">Column.alias</a>, <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.select.html\">DataFrame.select</a>, <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lower.html\">lower</a></p></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmmbqjYgInfy"
   },
   "source": [
    "#### **Expected output**: First 10 rows of the resulting dataframe with a single column name `lowerfirst100`\n",
    "\n",
    "NOTE:  Pass <code>truncate=False</code> as argument to <code>DataFrame.show()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "a3da1a3b-bca8-4f4f-8076-453219d0f3ab",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "deletable": false,
    "editable": true,
    "id": "Xdlp_GLUInfy",
    "outputId": "c452fc31-df97-4707-c50b-aa3b0d51fd6d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|lowerfirst100                                                                                       |\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|this was the first time i read garcia-aguilera.  i came upon the name of this book on live with regi|\n",
      "|also after going through all of daisy's perils ... i closed the book with a feeling i had grown emot|\n",
      "|as with all of ms. garcia-aguilera's books, i think this is a must read, impossible to put down. suc|\n",
      "|i've not read any of ms aguilera's works before, but after having just finished one hot summer i'm g|\n",
      "|this romance novel is right up there with the rest of her amazing mystery novels.  being a guy, i wa|\n",
      "|carolina garcia aguilera has done it again.  she's written another highly enjoyable book and infused|\n",
      "|not only can she write mysteries,but she sure can write a love story! this was \"one hot summer\" read|\n",
      "|once again garcia-aguilera has written a book that i just can't put down. i have read and love all h|\n",
      "|the timing is just right for a good book. actually, it's long overdue. therefore, i highly recommend|\n",
      "|engaging. dark. reading the book you could almost feel the train wreck about to happen.  the collisi|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring, lower\n",
    "\n",
    "# Assuming the text column is named \"text_column\"\n",
    "df_transformed = df.select(\n",
    "    lower(substring(\"value\", 1, 100)).alias(\"lowerfirst100\")\n",
    ")\n",
    "\n",
    "# Show the first 10 rows of the new dataframe\n",
    "df_transformed.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrmwmEMLInfy"
   },
   "source": [
    "### 6. Save results to HDFS - 1 point\n",
    "\n",
    "NOTE: Spark uses a distributed memory system, and stores working data in fragments known as \"partitions\". This is advantageous when a Spark cluster spans multiple machines, as each machine will only require part of the working data to do its own job. By default, Spark will save each of these data partitions into a individual file to avoid I/O collisions. We want only one output file, so we'll need to fuse all the data into a single partition first. \n",
    "\n",
    "Your task: \n",
    "<ol>\n",
    "    <li type=\"a\">Coalesce the previous dataframe to one partition using <code>DataFrame.coalesce(1)</code>. This returns a 1-partition dataframe. This makes sure that all our results will end up in the same text file.</li>\n",
    "    <li type = \"a\">Save the 1-partition dataframe to HDFS using the <code>DataFrame.write.text(&ltpath&gt)</code> method to the root directory of the HDFS, i.e. <code>hdfs:///BookReviews_1M_lowerfirst100.txt</code>.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPi15W18Infy"
   },
   "source": [
    "#### **Expected output**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": true,
    "id": "XW9nNYdJInfy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_single_partition = df_transformed.coalesce(1)\n",
    "\n",
    "df_single_partition.write.mode(\"overwrite\").text(\"hdfs:///Demo1-HDFS/BookReviews_1M_lowerfirst100.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counterintuitively, the resultant file saved in the step above is actually a folder, which contains individually saved files from each partition of the saved dataframe. <br> <br>\n",
    "Now, use an HDFS command to show the contents of the resulting folder on HDFS from the last step in the cell below. <br>\n",
    "You will need to include ‘!’ before the HDFS command for Jupyter Notebook to recognize it as an operating system command. For instance '! pwd' displays the path name of your current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/MGTA466:Session1/Demo1-Local\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LO77fkPInfz"
   },
   "source": [
    "#### **Expected output**: List of files in the result directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "9badd4ba-63a2-42c4-9dc7-8df9ecaef8f3",
    "deletable": false,
    "editable": true,
    "id": "c5f2mXp8Infz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 jovyan supergroup          0 2025-02-15 16:21 hdfs:///Demo1-HDFS/BookReviews_1M_lowerfirst100.txt/_SUCCESS\n",
      "-rw-r--r--   1 jovyan supergroup   81404214 2025-02-15 16:21 hdfs:///Demo1-HDFS/BookReviews_1M_lowerfirst100.txt/part-00000-5b8e635d-fcc2-46c8-8143-0129a1fbf49d-c000.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls hdfs:///Demo1-HDFS/BookReviews_1M_lowerfirst100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPJP-KEiInfz"
   },
   "source": [
    "### 7. Copy the results from HDFS to the local file system - 0.5 points\n",
    "\n",
    "Now that we have our results stored in HDFS, we need to copy it back to the local file system to access it. This process may sound cumbersome, but it is a necessary result of Spark and Hadoop's distributed architecture, and their ability to scale up to arbitrarily large datasets and computing operations. \n",
    "\n",
    "Copying the results from HDFS to the local file system is fairly simple. Here are the steps:\n",
    "<ol>\n",
    "    <li type =\"a\" >Run an hdfs command in the terminal to list the root directory of the HDFS. You should see the text file that you have saved. Counterintuitively, this text file is actually a folder, which contains individually saved files from each partition of the saved dataframe (see above for data partitioning). </li>\n",
    "    <li type =\"a\">Run another hdfs command to see what's inside the saved folder. Since we made sure to coalesce our dataframe to just one partition, we should expect to find only one saved partition in this folder, saved also as a txt. Note the name of this file, it should look something like <code>part-00000-xx.....xx.txt</code>. </li>\n",
    "    <li type =\"a\">Now, copy the resultant txt file from HDFS to the current folder on your local file system using an hdfs command in the terminal. You may rename this file to something more interpretable like <code>results.txt</code>.</li>\n",
    "    <li type =\"a\">We only want you to submit a <code>.txt</code> containing the first 31 lines of the results file. To do this, you can use the command <code>head -n 31 results.txt > results_30.txt</code>.</li>\n",
    "</ol>\n",
    "\n",
    "#### **Expected output**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxr-xr-x   - jovyan supergroup          0 2025-02-15 16:05 /BookReviews_1M_lowerfirst100.txt\n",
      "-rw-r--r--   1 jovyan supergroup  219041604 2025-02-15 15:59 /Demo1-\n",
      "drwxr-xr-x   - jovyan supergroup          0 2025-02-15 16:21 /Demo1-HDFS\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 jovyan supergroup          0 2025-02-15 16:21 hdfs:///Demo1-HDFS/BookReviews_1M_lowerfirst100.txt/_SUCCESS\n",
      "-rw-r--r--   1 jovyan supergroup   81404214 2025-02-15 16:21 hdfs:///Demo1-HDFS/BookReviews_1M_lowerfirst100.txt/part-00000-5b8e635d-fcc2-46c8-8143-0129a1fbf49d-c000.txt\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls hdfs:///Demo1-HDFS/BookReviews_1M_lowerfirst100.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -get hdfs:///Demo1-HDFS/BookReviews_1M_lowerfirst100.txt/part-00000-5b8e635d-fcc2-46c8-8143-0129a1fbf49d-c000.txt results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 31 results.txt > results_30.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 a. Stop Spark Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i_FdeZVInfz"
   },
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 b. Stop HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping HDFS ...\n"
     ]
    }
   ],
   "source": [
    "# Stop HDFS\n",
    "\n",
    "# !$HADOOP_HOME/stop-dfs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG42VCLWInfz"
   },
   "source": [
    "### 9. Submission of `results_30.txt` - 2 points\n",
    "\n",
    "#### **Expected output**(in the results_30.txt file) - First 31 lines of the results in step 5.\n",
    "The autograder will check whether the results that you submit in the `results_30.txt` file matches **exactly** with the expected results or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5nVMYsxInfz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
